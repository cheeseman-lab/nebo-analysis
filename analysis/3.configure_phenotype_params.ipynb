{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Phenotype Parameters\n",
    "\n",
    "This notebook should be used as a test for ensuring correct phenotype image loading and processing before running phenotype module.\n",
    "Cells marked with <font color='red'>SET PARAMETERS</font> contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Fixed parameters for phenotype processing\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing. Absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "CUDA available: True\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: Tesla T4\n",
      "CUDA version (runtime): 12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Verify acess to GPU\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version (runtime):\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v4.0.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 11:25:15.335180: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from microfilm.microplot import Microimage\n",
    "\n",
    "from lib.shared.align import apply_custom_offsets\n",
    "from lib.shared.configuration_utils import (\n",
    "    CONFIG_FILE_HEADER,\n",
    "    create_micropanel,\n",
    "    random_cmap,\n",
    "    image_segmentation_annotations,\n",
    ")\n",
    "from lib.shared.file_utils import get_filename\n",
    "from lib.shared.illumination_correction import apply_ic_field\n",
    "from lib.phenotype.align_channels import align_phenotype_channels\n",
    "from lib.shared.segment_cellpose import estimate_diameters, segment_cellpose\n",
    "from lib.shared.segment_microsam import segment_microsam\n",
    "# from lib.shared.segment_stardist import segment_stardist\n",
    "from lib.phenotype.identify_cytoplasm_cellpose import (\n",
    "    identify_cytoplasm_cellpose,\n",
    ")\n",
    "from lib.shared.extract_phenotype_minimal import extract_phenotype_minimal\n",
    "from lib.phenotype.identify_vacuoles import segment_vacuoles, create_vacuole_boundary_visualization\n",
    "from lib.phenotype.extract_phenotype_cp_multichannel import (\n",
    "    extract_phenotype_cp_multichannel,\n",
    ")\n",
    "from lib.phenotype.extract_phenotype_vacuoles import extract_phenotype_vacuoles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Parameters for testing phenotype processing\n",
    "\n",
    "- `TEST_PLATE`, `TEST_WELL`, `TEST_TILE`: Plate/well/tile combination used for configuring parameters in this notebook.\n",
    "\n",
    "### Channels\n",
    "- `CHANNEL_NAMES`: A list of names for each channel in your phenotyping image. These names will be used in the output data frame to label the features extracted from each channel.\n",
    "- `CHANNEL_CMAPS`: A list of color maps to use when showing channel microimages. These need to be a Matplotlib or microfilm colormap. We recommend using: `[\"pure_red\", \"pure_green\", \"pure_blue\", \"pure_cyan\", \"pure_magenta\", \"pure_yellow\"]`.\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "- `FOCI_CHANNEL`: Determines which channel is used for foci detection. This should be set to the index of the channel containing the marker you want to detect foci for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for testing\n",
    "TEST_PLATE = 1\n",
    "TEST_WELL = \"A3\"\n",
    "TEST_TILE = 4075\n",
    "WILDCARDS = dict(well=TEST_WELL, tile=TEST_TILE)\n",
    "\n",
    "CHANNEL_NAMES = [\"DAPI\", \"ConA\", \"Stat6\", \"Mitotracker\", \"DAPI2\", \"NHS_ester\", \"DAPI3\", \"Tubulin\", \"WGA\", \"cMYC\", \"CDPK1\"]\n",
    "CHANNEL_CMAPS = [\"pure_cyan\", \"pure_green\", \"pure_red\", \"pure_yellow\", \"pure_blue\", \"pure_green\", \"pure_blue\", \"pure_green\", \"pure_red\", \"pure_yellow\", \"pure_magenta\"]\n",
    "\n",
    "# parameters for feature extraction\n",
    "FOCI_CHANNEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConstructorError",
     "evalue": "could not determine a constructor for the tag 'tag:yaml.org,2002:python/tuple'\n  in \"config/config.yml\", line 60, column 8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConstructorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load config file\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(CONFIG_FILE_PATH, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m config_file:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     config = \u001b[43myaml\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# load test image data\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading test image...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/__init__.py:125\u001b[39m, in \u001b[36msafe_load\u001b[39m\u001b[34m(stream)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msafe_load\u001b[39m(stream):\n\u001b[32m    118\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[33;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \u001b[33;03m    to be safe for untrusted input.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/__init__.py:81\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(stream, Loader)\u001b[39m\n\u001b[32m     79\u001b[39m loader = Loader(stream)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     loader.dispose()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:51\u001b[39m, in \u001b[36mBaseConstructor.get_single_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m node = \u001b[38;5;28mself\u001b[39m.get_single_node()\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstruct_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:60\u001b[39m, in \u001b[36mBaseConstructor.construct_document\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mself\u001b[39m.state_generators = []\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m generator \u001b[38;5;129;01min\u001b[39;00m state_generators:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m.constructed_objects = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:413\u001b[39m, in \u001b[36mSafeConstructor.construct_yaml_map\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    411\u001b[39m data = {}\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m data\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstruct_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m data.update(value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:218\u001b[39m, in \u001b[36mSafeConstructor.construct_mapping\u001b[39m\u001b[34m(self, node, deep)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, MappingNode):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m.flatten_mapping(node)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:143\u001b[39m, in \u001b[36mBaseConstructor.construct_mapping\u001b[39m\u001b[34m(self, node, deep)\u001b[39m\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, collections.abc.Hashable):\n\u001b[32m    141\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ConstructorError(\u001b[33m\"\u001b[39m\u001b[33mwhile constructing a mapping\u001b[39m\u001b[33m\"\u001b[39m, node.start_mark,\n\u001b[32m    142\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfound unhashable key\u001b[39m\u001b[33m\"\u001b[39m, key_node.start_mark)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstruct_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     mapping[key] = value\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mapping\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:100\u001b[39m, in \u001b[36mBaseConstructor.construct_object\u001b[39m\u001b[34m(self, node, deep)\u001b[39m\n\u001b[32m     98\u001b[39m             constructor = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.construct_mapping\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tag_suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     data = \u001b[43mconstructor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m     data = constructor(\u001b[38;5;28mself\u001b[39m, tag_suffix, node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/lab/solexa_lourido/USERS/AK/miniforge3/envs/brieflow_main_env/lib/python3.11/site-packages/yaml/constructor.py:427\u001b[39m, in \u001b[36mSafeConstructor.construct_undefined\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstruct_undefined\u001b[39m(\u001b[38;5;28mself\u001b[39m, node):\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ConstructorError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    428\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcould not determine a constructor for the tag \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % node.tag,\n\u001b[32m    429\u001b[39m             node.start_mark)\n",
      "\u001b[31mConstructorError\u001b[39m: could not determine a constructor for the tag 'tag:yaml.org,2002:python/tuple'\n  in \"config/config.yml\", line 60, column 8"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# load test image data\n",
    "print(\"Loading test image...\")\n",
    "ROOT_FP = Path(config[\"all\"][\"root_fp\"])\n",
    "PREPROCESS_FP = ROOT_FP / \"preprocess\"\n",
    "phenotype_test_image_path = str(\n",
    "    PREPROCESS_FP\n",
    "    / \"images\"\n",
    "    / \"phenotype\"\n",
    "    / get_filename(\n",
    "        {\"plate\": TEST_PLATE, \"well\": TEST_WELL, \"tile\": TEST_TILE},\n",
    "        \"image\",\n",
    "        \"tiff\",\n",
    "    )\n",
    ")\n",
    "phenotype_test_image = imread(phenotype_test_image_path)\n",
    "\n",
    "print(\"Applying illumination correction...\")\n",
    "# Read the illumination correction file\n",
    "ic_field_path = str(\n",
    "    PREPROCESS_FP\n",
    "    / \"ic_fields\"\n",
    "    / \"phenotype\"\n",
    "    / get_filename({\"plate\": TEST_PLATE, \"well\": TEST_WELL}, \"ic_field\", \"tiff\")\n",
    ")\n",
    "ic_field = imread(ic_field_path)\n",
    "\n",
    "# This corresponds to the 'apply_illumination_correction' rule in Snakemake\n",
    "corrected_image = apply_ic_field(phenotype_test_image, correction=ic_field)\n",
    "\n",
    "# Create and display micropanel of corrected images\n",
    "print(\"Example corrected image:\")\n",
    "corrected_microimages = [\n",
    "    Microimage(\n",
    "        corrected_image[i], channel_names=CHANNEL_NAMES[i], cmaps=CHANNEL_CMAPS[i]\n",
    "    )\n",
    "    for i in range(corrected_image.shape[0])\n",
    "]\n",
    "corrected_panel = create_micropanel(corrected_microimages, add_channel_label=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Aligning (optional)\n",
    "\n",
    "- `ALIGN`: Whether to conduct alignment. This is suggested **unless** each image is captured with each channel consecutively. \n",
    "- `TARGET`: Index of the channel that other channels will be aligned to.\n",
    "- `SOURCE`: Index of the channel to align with the target.\n",
    "- `RIDERS`: Additional channel indices that should follow the same alignment as the source channel.\n",
    "- `REMOVE_CHANNEL`: Specifies whether to remove channels after alignment. In the case of duplicate channels that are used to align the image, should be set to `source`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set alignment parameters \n",
    "ALIGN = False\n",
    "\n",
    "# Define single alignment configuration for all wells with multiple steps\n",
    "ALIGNMENTS = {\n",
    "    1: {\n",
    "        \"steps\": [\n",
    "            # First alignment step\n",
    "            {\n",
    "                \"target\": 0,  # DAPI from first round\n",
    "                \"source\": 4,  # DAPI2 (assuming this is position 5)\n",
    "                \"riders\": [5],  # Other channels in second round\n",
    "                \"remove_channel\": \"source\",  # Remove DAPI2 after alignment\n",
    "            },\n",
    "            # Third alignment step\n",
    "            {\n",
    "                \"target\": 0,  # DAPI from first round\n",
    "                \"source\": 5,  # DAPI3 (assuming this is position 10)\n",
    "                \"riders\": [6, 7, 8, 9],  # Other channels in third round\n",
    "                \"remove_channel\": \"source\"  # Remove DAPI3 after alignment\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ALIGN:\n",
    "    print(\"Aligning channels...\")\n",
    "    # Get alignment configuration for the current plate\n",
    "    plate_config = ALIGNMENTS.get(TEST_PLATE)\n",
    "    \n",
    "    if plate_config:\n",
    "        # Start with the corrected image\n",
    "        aligned_image = corrected_image\n",
    "        \n",
    "        # Check if this is a multi-step alignment (has \"steps\" key)\n",
    "        if \"steps\" in plate_config:\n",
    "            print(f\"Performing multi-step alignment for plate {TEST_PLATE}...\")\n",
    "            \n",
    "            # Apply each alignment step in sequence\n",
    "            for step_num, step in enumerate(plate_config[\"steps\"], 1):\n",
    "                print(f\"  Step {step_num}: Aligning {step['target']} (target) with {step['source']} (source)\")\n",
    "                aligned_image,_ = align_phenotype_channels(\n",
    "                    aligned_image,\n",
    "                    target=step[\"target\"],\n",
    "                    source=step[\"source\"],\n",
    "                    riders=step[\"riders\"],\n",
    "                    remove_channel=step[\"remove_channel\"],\n",
    "                )\n",
    "                CHANNEL_NAMES.pop(step[\"source\"])\n",
    "                CHANNEL_CMAPS.pop(step[\"source\"])\n",
    "        else:\n",
    "            # Single-step alignment\n",
    "            print(f\"Performing single-step alignment for plate {TEST_PLATE}...\")\n",
    "            aligned_image,_ = align_phenotype_channels(\n",
    "                corrected_image,\n",
    "                target=plate_config[\"target\"],\n",
    "                source=plate_config[\"source\"],\n",
    "                riders=plate_config[\"riders\"],\n",
    "                remove_channel=plate_config[\"remove_channel\"],\n",
    "            )\n",
    "    else:\n",
    "        # No configuration found for this plate\n",
    "        print(f\"Warning: No alignment configuration found for plate {TEST_PLATE}\")\n",
    "        aligned_image = corrected_image\n",
    "else:\n",
    "    aligned_image = corrected_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom alignment parameters\n",
    "ALIGN_CUSTOM = True\n",
    "# CUSTOM_CHANNELS = [\"NHS_ester\"]  # Channels to apply custom offset to\n",
    "CUSTOM_OFFSET_YX = {\n",
    "    5: (-5, 15),    # R2\n",
    "    7: (-15, 35),   # R3\n",
    "    8: (-15, 35),\n",
    "    9: (-15, 35),\n",
    "    10: (-15, 35)\n",
    "}\n",
    "CUSTOM_CHANNEL_REMOVE = [4, 6]  # Channels to remove after custom alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.shared.image_utils import remove_channels\n",
    "# Custom alignment process (applies after standard alignment)\n",
    "if ALIGN_CUSTOM:\n",
    "    print(\"Applying custom channel offsets...\")\n",
    "    for index, (y, x) in CUSTOM_OFFSET_YX.items():\n",
    "        print(f\"Channel index {index}\")\n",
    "        print(f\"  Custom offset (y, x): {y}, {x}\")\n",
    "\n",
    "    # Apply custom offsets directly using the channel indices from config\n",
    "    aligned_image = apply_custom_offsets(\n",
    "        aligned_image,\n",
    "        offsets_dict=CUSTOM_OFFSET_YX,\n",
    "    )\n",
    "    \n",
    "    # Optional: remove channels after custom alignment\n",
    "    if CUSTOM_CHANNEL_REMOVE is not None:\n",
    "        print(f\"Removing channels after custom alignment: {CUSTOM_CHANNEL_REMOVE}\")\n",
    "        aligned_image = remove_channels(aligned_image, CUSTOM_CHANNEL_REMOVE)\n",
    "# Update channel names and colormaps after alignment\n",
    "for index in sorted(CUSTOM_CHANNEL_REMOVE, reverse=True):\n",
    "    CHANNEL_NAMES.pop(index)\n",
    "    CHANNEL_CMAPS.pop(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save aligned image as multichannel tiff in root directory\n",
    "from tifffile import imwrite\n",
    "imwrite(\"test_output.tiff\", aligned_image.astype(np.float32), photometric=\"minisblack\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_NAMES, CHANNEL_CMAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Segmentation\n",
    "\n",
    "#### Select Segmentation Method\n",
    "- `SEGMENTATION_METHOD`: Choose from \"cellpose\", \"microsam\", or \"stardist\" for cell segmentation.\n",
    "\n",
    "#### Common Parameters\n",
    "- `CYTO_CHANNEL`: Channel to use for cell detection (typically \"PHALLOIDIN\")\n",
    "- `HELPER_CHANNEL`: Optional channel to use for cell detection. Set to None if you only want to use CYTO_CHANNEL only.\n",
    "- `GPU`: Set to True to use GPU acceleration (if available)\n",
    "- `RECONCILE`: Method for reconciling nuclei and cell masks (typically \"contained_in_cells\", which allows more than one nucleus per cell and is useful for cells that are dividing)\n",
    "\n",
    "#### Cellpose Parameters (if using \"cellpose\")\n",
    "- `CELLPOSE_MODEL`: CellPose model to use (if CPSAM was re-trained). Default is \"cpsam\".\n",
    "- `FLOW_THRESHOLD`: Flow threshold for Cellpose segmentation. Default is 0.4. Range 0.1 to 3.0.\n",
    "- `CELLPROB_THRESHOLD`: Cell probability threshold for Cellpose. Default is 0. Range â€“6.0 to +6.0.\n",
    "- Note: Nuclei and cell diameters will be estimated automatically.\n",
    "\n",
    "#### MicroSAM Parameters (if using \"microsam\")\n",
    "- `MICROSAM_MODEL`: MicroSAM model type. Default is \"vit_b_lm\".\n",
    "- `POINTS_PER_SIDE`: Number of points to sample along each side of the image. Default is 32.\n",
    "- `POINTS_PER_BATCH`: Number of points to process in one batch. Default is 16.\n",
    "- `STABILITY_SCORE_THRESH`: Threshold for stability score. Default is 0.95.\n",
    "- `PRED_IOU_THRESH`: Threshold for predicted IoU. Default is 0.88.\n",
    "\n",
    "#### StarDist Parameters (if using \"stardist\")\n",
    "- `STARDIST_MODEL`: StarDist model type. Default is \"2D_versatile_fluo\".\n",
    "- `PROB_THRESH`: Probability threshold for segmentation. Default is 0.479071.\n",
    "- `NMS_THRESH`: Non-maximum suppression threshold. Default is 0.3.\n",
    "\n",
    "Note: You may want to adjust these parameters and run segmentation tests if you feel you are capturing too little or too much area for the masks. For cellpose, the nuclei and cell diameters will be automatically estimated, but can be manually adjusted if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters\n",
    "CYTO_CHANNEL = \"NHS_ester\"\n",
    "GPU = True\n",
    "RECONCILE = \"contained_in_cells\"\n",
    "DAPI_INDEX = CHANNEL_NAMES.index(\"DAPI\")\n",
    "CYTO_INDEX = CHANNEL_NAMES.index(CYTO_CHANNEL)\n",
    "\n",
    "# Select segmentation method\n",
    "SEGMENTATION_METHOD = \"cellpose\"\n",
    "\n",
    "if SEGMENTATION_METHOD == \"cellpose\":\n",
    "    # Parameters for CellPose method\n",
    "    CELLPOSE_MODEL = \"cpsam\"\n",
    "    HELPER_CHANNEL = \"Tubulin\"\n",
    "    HELPER_INDEX = CHANNEL_NAMES.index(HELPER_CHANNEL)\n",
    "    NUCLEI_FLOW_THRESHOLD = 0.4\n",
    "    NUCLEI_CELLPROB_THRESHOLD = 1\n",
    "    CELL_FLOW_THRESHOLD = 0.4 \n",
    "    CELL_CELLPROB_THRESHOLD = 1\n",
    "    SEGMENT_CELLS = True \n",
    "\n",
    "    # print(\"Estimating optimal cell and nuclei diameters...\")\n",
    "    # NUCLEI_DIAMETER, CELL_DIAMETER = estimate_diameters(\n",
    "    #     corrected_image,\n",
    "    #     dapi_index=DAPI_INDEX,\n",
    "    #     cyto_index=CYTO_INDEX,\n",
    "    #     cyto_model=CELLPOSE_MODEL,\n",
    "    # )\n",
    "\n",
    "elif SEGMENTATION_METHOD == \"microsam\":\n",
    "    # Parameters for MicroSAM method\n",
    "    MICROSAM_MODEL = \"vit_b_lm\"\n",
    "    POINTS_PER_SIDE = 32\n",
    "    POINTS_PER_BATCH = 16\n",
    "    STABILITY_SCORE_THRESH = 0.95\n",
    "    PRED_IOU_THRESH = 0.88\n",
    "\n",
    "elif SEGMENTATION_METHOD == \"stardist\":\n",
    "    # Parameters for StarDist method\n",
    "    STARDIST_MODEL = \"2D_versatile_fluo\"\n",
    "    PROB_THRESH = 0.479071\n",
    "    NMS_THRESH = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set cell diameter to 300\n",
    "NUCLEI_DIAMETER = 100\n",
    "CELL_DIAMETER = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Segmenting image with {SEGMENTATION_METHOD}...\")\n",
    "\n",
    "if SEGMENTATION_METHOD == \"cellpose\":\n",
    "    nuclei, cells = segment_cellpose(\n",
    "        aligned_image,\n",
    "        dapi_index=DAPI_INDEX,\n",
    "        cyto_index=CYTO_INDEX,\n",
    "        helper_index=HELPER_INDEX,\n",
    "        nuclei_diameter=NUCLEI_DIAMETER,\n",
    "        cell_diameter=CELL_DIAMETER,\n",
    "        cellpose_kwargs=dict(\n",
    "            nuclei_flow_threshold=NUCLEI_FLOW_THRESHOLD,\n",
    "            nuclei_cellprob_threshold=NUCLEI_CELLPROB_THRESHOLD,\n",
    "            cell_flow_threshold=CELL_FLOW_THRESHOLD,\n",
    "            cell_cellprob_threshold=CELL_CELLPROB_THRESHOLD,\n",
    "        ),\n",
    "        cyto_model=CELLPOSE_MODEL,\n",
    "        gpu=GPU,\n",
    "        reconcile=RECONCILE,\n",
    "    )\n",
    "\n",
    "elif SEGMENTATION_METHOD == \"microsam\":\n",
    "    nuclei = segment_microsam(\n",
    "        aligned_image,\n",
    "        dapi_index=DAPI_INDEX,\n",
    "        cyto_index=CYTO_INDEX,\n",
    "        model_type=MICROSAM_MODEL,\n",
    "        microsam_kwargs=dict(\n",
    "            points_per_side=POINTS_PER_SIDE,\n",
    "            points_per_batch=POINTS_PER_BATCH,\n",
    "            stability_score_thresh=STABILITY_SCORE_THRESH,\n",
    "            pred_iou_thresh=PRED_IOU_THRESH,\n",
    "        ),\n",
    "        gpu=GPU,\n",
    "        reconcile=RECONCILE,\n",
    "    )\n",
    "\n",
    "elif SEGMENTATION_METHOD == \"stardist\":\n",
    "    nuclei = segment_stardist(\n",
    "        aligned_image,\n",
    "        dapi_index=DAPI_INDEX,\n",
    "        cyto_index=CYTO_INDEX,\n",
    "        model_type=STARDIST_MODEL,\n",
    "        stardist_kwargs=dict(\n",
    "            prob_thresh=PROB_THRESH,\n",
    "            nms_thresh=NMS_THRESH,\n",
    "        ),\n",
    "        gpu=GPU,\n",
    "        reconcile=RECONCILE,\n",
    "    )\n",
    "\n",
    "# Create and display micropanel of nuclei segmentation\n",
    "print(\"Example microplots for DAPI channel and nuclei segmentation:\")\n",
    "nuclei_cmap = random_cmap(num_colors=len(np.unique(nuclei)))\n",
    "nuclei_seg_microimages = [\n",
    "    Microimage(\n",
    "        aligned_image[DAPI_INDEX],\n",
    "        channel_names=\"DAPI\",\n",
    "        cmaps=CHANNEL_CMAPS[DAPI_INDEX],\n",
    "    ),\n",
    "    Microimage(nuclei, cmaps=nuclei_cmap, channel_names=\"Nuclei\"),\n",
    "]\n",
    "nuclei_seg_panel = create_micropanel(nuclei_seg_microimages, add_channel_label=True)\n",
    "plt.show()\n",
    "\n",
    "# cells = np.zeros_like(nuclei)\n",
    "\n",
    "# Create and display micropanel of segmented cells\n",
    "print(\"Example microplots for merged channels and cells segmentation:\")\n",
    "cells_cmap = random_cmap(num_colors=len(np.unique(cells)))\n",
    "cells_seg_microimages = [\n",
    "    Microimage(\n",
    "        aligned_image[CYTO_INDEX],\n",
    "        channel_names=\"NHS_ester\",\n",
    "        cmaps=CHANNEL_CMAPS[CYTO_INDEX],\n",
    "    ),\n",
    "    Microimage(cells, cmaps=cells_cmap, channel_names=\"Cells\"),\n",
    "]\n",
    "cells_seg_panel = create_micropanel(cells_seg_microimages, add_channel_label=True)\n",
    "plt.show()\n",
    "\n",
    "# Create and display micropanel of annotated phenotype data\n",
    "print(\"Example microplot for phenotype data annotated with segmentation:\")\n",
    "annotated_data = image_segmentation_annotations(aligned_image[CYTO_INDEX], nuclei, cells)\n",
    "annotated_microimage = [\n",
    "    Microimage(\n",
    "        annotated_data, channel_names=\"Merged\", cmaps=[\"pure_green\"] + [\"pure_cyan\"]\n",
    "    )\n",
    "]\n",
    "annotated_panel = create_micropanel(\n",
    "    annotated_microimage, num_cols=1, figscaling=10, add_channel_label=False\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Create and display micropanel of cytoplasms\n",
    "print(\"Example microplots for cytoplasms relative to nuclei:\")\n",
    "cytoplasms = identify_cytoplasm_cellpose(nuclei, cells)\n",
    "cytoplasms_cmap = random_cmap(num_colors=len(np.unique(cytoplasms)))\n",
    "cytoplasms_microimages = [\n",
    "    Microimage(nuclei, cmaps=nuclei_cmap, channel_names=\"Nuclei\"),\n",
    "    Microimage(cytoplasms, cmaps=cytoplasms_cmap, channel_names=\"Cytoplasms\"),\n",
    "]\n",
    "cytoplasms_panel = create_micropanel(cytoplasms_microimages, add_channel_label=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract minimal phenotype data\n",
    "phenotype_minimal = extract_phenotype_minimal(nuclei, nuclei, WILDCARDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>SET PARAMETERS</font>\n",
    "\n",
    "### Vacuole detection (optional)\n",
    "\n",
    "- `VACUOLE_DETECTION`: Whether to perform vacuole detection.\n",
    "- `VACUOLE_CHANNEL`: Name of the channel used for vacuole detection (typically CDPK1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set vacuole parameters\n",
    "VACUOLE_DETECTION = True\n",
    "VACUOLE_CHANNEL = \"CDPK1\"\n",
    "VACUOLE_MIN_SIZE = 25         \n",
    "VACUOLE_MAX_SIZE = 200\n",
    "\n",
    "# Derive vacuole channel index from CHANNEL_NAMES\n",
    "if VACUOLE_DETECTION:\n",
    "    VACUOLE_CHANNEL_INDEX = CHANNEL_NAMES.index(VACUOLE_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VACUOLE_CHANNEL_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment vacuoles if enabled\n",
    "if VACUOLE_DETECTION:\n",
    "    print(f\"Performing vacuole segmentation with {VACUOLE_CHANNEL}...\")\n",
    "    \n",
    "    vacuole_masks, cell_vacuole_table, updated_cytoplasm_masks = segment_vacuoles(\n",
    "        image=corrected_image,\n",
    "        vacuole_channel_index=VACUOLE_CHANNEL_INDEX,\n",
    "        nuclei_channel_index=VACUOLE_CHANNEL_INDEX, \n",
    "        cell_masks=cells,\n",
    "        cytoplasm_masks=cytoplasms,\n",
    "        min_size=VACUOLE_MIN_SIZE,\n",
    "        max_size=VACUOLE_MAX_SIZE,\n",
    "        nuclei_min_distance=5,\n",
    "        nuclei_centroids=phenotype_minimal\n",
    "    )\n",
    "    cell_summary = cell_vacuole_table['cell_summary']\n",
    "    vacuole_cell_mapping = cell_vacuole_table['vacuole_cell_mapping']\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Found vacuoles in {cell_summary['has_vacuole'].sum()} out of {len(cell_summary)} cells\")\n",
    "    print(f\"Average vacuoles per cell with vacuoles: {cell_summary.loc[cell_summary['has_vacuole'], 'num_vacuoles'].mean():.2f}\")\n",
    "    print(f\"Average vacuole area ratio: {cell_summary['vacuole_area_ratio'].mean():.4f}\")\n",
    "    print(f\"Total nuclei detected within vacuoles: {cell_summary['total_nuclei_in_vacuoles'].sum()}\")\n",
    "    print(f\"Number of multinucleated vacuoles: {cell_summary['multinucleated_vacuole_count'].sum()}\")\n",
    "    \n",
    "    # Create standard visualizations\n",
    "    print(\"Example microplots for vacuole channel and vacuole segmentation:\")\n",
    "    vacuole_cmap = random_cmap(num_colors=len(np.unique(vacuole_masks)))\n",
    "    vacuole_microimages = [\n",
    "        Microimage(\n",
    "            corrected_image[VACUOLE_CHANNEL_INDEX],\n",
    "            channel_names=VACUOLE_CHANNEL,\n",
    "            cmaps=\"gray\",\n",
    "        ),\n",
    "        Microimage(vacuole_masks, cmaps=vacuole_cmap, channel_names=\"Vacuoles\"),\n",
    "    ]\n",
    "    vacuole_panel = create_micropanel(vacuole_microimages, add_channel_label=True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Create enhanced boundary visualization with peaks\n",
    "    print(\"Enhanced visualization with cell boundaries, vacuole boundaries, and detected peaks:\")\n",
    "    boundary_panel = create_vacuole_boundary_visualization(\n",
    "        corrected_image,\n",
    "        VACUOLE_CHANNEL_INDEX,\n",
    "        cell_masks=cells,\n",
    "        vacuole_masks=vacuole_masks,\n",
    "        vacuole_cell_mapping=vacuole_cell_mapping,\n",
    "        channel_names=CHANNEL_NAMES,\n",
    "        show_nuclei_peaks=True\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the two DataFrames from the dictionary\n",
    "cell_summary_df = cell_vacuole_table['cell_summary']\n",
    "vacuole_cell_mapping_df = cell_vacuole_table['vacuole_cell_mapping']\n",
    "\n",
    "# Display the cell summary DataFrame\n",
    "print(\"Cell Summary DataFrame:\")\n",
    "display(cell_summary_df)\n",
    "\n",
    "# Display the vacuole-cell mapping DataFrame\n",
    "print(\"\\nVacuole-Cell Mapping DataFrame:\")\n",
    "display(vacuole_cell_mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting phenotype features:\")\n",
    "phenotype_cp = extract_phenotype_cp_multichannel(\n",
    "    aligned_image,\n",
    "    nuclei=nuclei,\n",
    "    cells=cells,\n",
    "    wildcards=WILDCARDS,\n",
    "    cytoplasms=cytoplasms,\n",
    "    foci_channel=FOCI_CHANNEL,\n",
    "    channel_names=CHANNEL_NAMES,\n",
    ")\n",
    "\n",
    "phenotype_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract phenotype features for vacuoles\n",
    "vacuole_phenotype = extract_phenotype_vacuoles(\n",
    "    aligned_image,\n",
    "    vacuoles=vacuole_masks,\n",
    "    vacuole_cell_mapping_df=cell_vacuole_table['vacuole_cell_mapping'],\n",
    "    wildcards=WILDCARDS,\n",
    "    foci_channel=FOCI_CHANNEL, \n",
    "    channel_names=CHANNEL_NAMES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuole_phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove channel names from feature names\n",
    "def remove_channel_name(feature, channels):\n",
    "    for channel in channels:\n",
    "        feature = feature.replace(f\"_{channel}\", \"\")\n",
    "    return feature\n",
    "\n",
    "\n",
    "# Remove label, well, tile and isolate remaining feature names\n",
    "filtered_features = [\n",
    "    feature\n",
    "    for feature in phenotype_cp.columns.tolist()\n",
    "    if feature not in [\"label\", \"well\", \"tile\"]\n",
    "]\n",
    "\n",
    "# Apply the function to remove channel names\n",
    "feature_types = [\n",
    "    remove_channel_name(feature, CHANNEL_NAMES) for feature in filtered_features\n",
    "]\n",
    "\n",
    "# Get unique feature types\n",
    "unique_feature_types = sorted(set(feature_types))\n",
    "\n",
    "print(\"Unique feature types:\")\n",
    "unique_feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add phenotype process parameters to config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mode` parameter in the config file determines how Snakemake will execute parameter searches for segmentation optimization. Setting the `mode` to `segment_phenotype_paramsearch` will systematically explore combinations of:\n",
    "\n",
    "1. Size Parameters:\n",
    "   - `nuclei_diameter`: Expected diameter of cell nuclei\n",
    "   - `cell_diameter`: Expected diameter of cell cytoplasm\n",
    "   \n",
    "2. CellPose Parameters:\n",
    "   - `flow_threshold`: Controls sensitivity of segmentation boundaries (default value 0.4)\n",
    "     - Lower values: More aggressive segmentation, may over-segment\n",
    "     - Higher values: More conservative, may miss cell boundaries\n",
    "   - `cellprob_threshold`: Controls cell detection confidence (default value 0)\n",
    "     - Lower values: Detects more potential cells, may include false positives\n",
    "     - Higher values: More stringent detection, may miss weaker signals\n",
    "\n",
    "The parameter search will:\n",
    "1. Generate segmentations using different parameter combinations\n",
    "2. Save results for each combination\n",
    "3. Allow you to visually inspect results to choose optimal values\n",
    "4. Help identify the best balance between over- and under-segmentation\n",
    "\n",
    "Running these parameter searches is a time and resource intensive process and should only be done on a small subset of the tiles in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuples to lists in your offset dictionary\n",
    "CUSTOM_OFFSET_YX_LISTS = {k: list(v) for k, v in CUSTOM_OFFSET_YX.items()}\n",
    "\n",
    "# Add phenotype section\n",
    "config[\"phenotype\"] = {\n",
    "    \"foci_channel\": FOCI_CHANNEL,\n",
    "    \"channel_names\": CHANNEL_NAMES,\n",
    "    \"align\": ALIGN_CUSTOM,\n",
    "    \"offsets_dict\": CUSTOM_OFFSET_YX,\n",
    "    \"remove_channel_custom\": CUSTOM_CHANNEL_REMOVE,\n",
    "    \"dapi_index\": DAPI_INDEX,\n",
    "    \"cyto_index\": CYTO_INDEX,\n",
    "    \"segmentation_method\": SEGMENTATION_METHOD,\n",
    "    \"segment_cells\": SEGMENT_CELLS,\n",
    "    \"reconcile\": RECONCILE,\n",
    "    \"gpu\": GPU,\n",
    "    \"mode\": None,\n",
    "}\n",
    "\n",
    "# Add method-specific parameters based on segmentation method\n",
    "if SEGMENTATION_METHOD == \"cellpose\":\n",
    "    config[\"phenotype\"].update({\n",
    "        \"nuclei_diameter\": NUCLEI_DIAMETER,\n",
    "        \"cell_diameter\": CELL_DIAMETER,\n",
    "        \"nuclei_flow_threshold\": NUCLEI_FLOW_THRESHOLD,\n",
    "        \"nuclei_cellprob_threshold\": NUCLEI_CELLPROB_THRESHOLD,\n",
    "        \"cell_flow_threshold\": CELL_FLOW_THRESHOLD,\n",
    "        \"cell_cellprob_threshold\": CELL_CELLPROB_THRESHOLD,\n",
    "        \"cyto_model\": CELLPOSE_MODEL,\n",
    "    })\n",
    "elif SEGMENTATION_METHOD == \"microsam\":\n",
    "    config[\"phenotype\"].update({\n",
    "        \"microsam_model\": MICROSAM_MODEL,\n",
    "        \"points_per_side\": POINTS_PER_SIDE,\n",
    "        \"points_per_batch\": POINTS_PER_BATCH,\n",
    "        \"stability_score_thresh\": STABILITY_SCORE_THRESH,\n",
    "        \"pred_iou_thresh\": PRED_IOU_THRESH,\n",
    "    })\n",
    "elif SEGMENTATION_METHOD == \"stardist\":\n",
    "    config[\"phenotype\"].update({\n",
    "        \"stardist_model\": STARDIST_MODEL,\n",
    "        \"prob_thresh\": PROB_THRESH,\n",
    "        \"nms_thresh\": NMS_THRESH,\n",
    "    })\n",
    "\n",
    "if ALIGN:\n",
    "    config[\"phenotype\"][\"alignments\"] = ALIGNMENTS\n",
    "\n",
    "if VACUOLE_DETECTION:\n",
    "    config[\"phenotype\"].update({\n",
    "        \"vacuole_detection\": VACUOLE_DETECTION,\n",
    "        \"vacuole_channel_index\": VACUOLE_CHANNEL_INDEX,\n",
    "        \"vacuole_min_size\": VACUOLE_MIN_SIZE,\n",
    "        \"vacuole_max_size\": VACUOLE_MAX_SIZE,\n",
    "    })\n",
    "\n",
    "# Write the updated configuration back with markdown-style comments\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory markdown-style comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(config, config_file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_main_env (conda)",
   "language": "python",
   "name": "brieflow_main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
